<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <html lang="en-US">
    <title>Raymond Xu</title>
    <meta name="author" content="Raymond Xu">
    <link href="styles/style.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed" rel="stylesheet" type='text/css'>
    <link rel="icon" type="image/png" sizes="96x96" href="images/favicon-96x96.png">
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-89449139-1', 'auto');
    ga('send', 'pageview');
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/velocity/1.4.0/velocity.min.js"></script>
    <meta http-equiv="Cache-control" content="public">
  </head>
  <body onload="openTab('projects')">
    <!-- Header and nav bar -->
    <div id="header">
      <div id="headerContent">
          <h1>Raymond Xu</h1>
        <ul id="bar">
          <li><a href="javascript:void(0)" class="menu" onclick="goToTab(event, 'index')" id="default">Home</a></li>
          <li><a href="javascript:void(0)" class="menu" onclick="goToTab(event, 'about')">About</a></li>
          <li><a href="javascript:void(0)" class="menu active" onclick="openTab('projects')">Projects</a></li>
          <li><a href="javascript:void(0)" class="menu" onclick="goToTab(event, 'courses')">Courses</a></li>
          <li><a href="javascript:void(0)" class="menu" onclick="goToTab(event, 'contact')">Contact</a></li>
        </ul>
      </div>
    </div>
    <!-- Projects -->
    <div class="tab" id="projects">
      <a class="top-anchor" id="top-projects"></a>
      <h5 id="pop3">Click on the projects to see descriptions and images.</h5>
      <!-- mert -->
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'Mert')"><div id="slideselect"><h2>Master of Engineering Design Project: Machine Learning in Sabuncu Lab</h2></div></a>
        <p>August 2017 - Present</p>
        <p>Image registration/optical flow of 3D brain MRIs: fast calibration & transformation into standard space. Utilized convolutional neural networks on modern machine learning frameworks PyTorch and TensorFlow.
        </p>
        <div style="text-align:center" id="Mert-expand">
          <a href="javascript:void(0)" onclick="slideOpen(event, 'Mert')"><button class="close">Expand</button></a>
        </div>
        <div class="rolldown" id="Mert">
          <h3>Project Goal</h3>
          <p>Currently, 3D image registration is done with an optimization process, which is slow. Because the database of brain MRI scans is so large, the transformations can be memorized by a machine given the shape of a given brain. The goal is to speed this process up with a convolutional nerual networks so the process becomes one step instead of iterative, speeding up the process. 
          </p>
          <p><img src="images/mert-brains.jpg" style="width:100%; max-width: 1000px;" class="images"></p>    
          <div style="text-align:center">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'Mert')"><button class="close">Collapse</button></a>
          </div>
        </div>
      </div>
      <!-- expedition -->
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'exp')"><div id="slideselect"><h2>Expedition Technologies</h2></div></a>
        <p>Dec 2017 - Present</p>
        <p>Used machine learning to classify 1D radar chirp emitters with an autoencoder neural network in TensorFlow. Fine tuned neural networks, and improved data preprocessing to increase accuracy and prevent over-fitting on classes with limited data. Scripted in python and bash, running code on AWS.
        </p>
        <div style="text-align:center" id="exp-expand">
          <a href="javascript:void(0)" onclick="slideOpen(event, 'exp')"><button class="close">Expand</button></a>
        </div>
        <div class="rolldown" id="exp">
          <p>My work with the company was entirely building and perfecting a single model to classify radar emitters; even when those radars emitted signals that were different frequencies, frequency patterns, time lengths, and bandwidths. </p>
          <h3>Architecture Description</h3>

          <p>The architecture involved taking FFT's of the data, doing a couple convolutional filters on groups of them, and then inputting each FFT into a long short-term memory network (LSTM), one per time step. The LSTM states then learned how to interpret the signals. The output of the the LSTM is trained with an autoencoder, with the loss being the comparison with the original signal. Then, then network is trained by attaching the LSTM to several dense neural network layers. The network was able to achieve >95% test accuracy on the emitter classification.
          </p>
          <p>This is the t-distributed stochastic neighbor embedding (tsne) viewing of the training data for the encodings of the dozen radar emitter classes. The data looks relatively separable. </p>
          <p><img src="images/train-tsne.jpg" style="width:100%; max-width: 1000px;" class="images"></p> 
          <p>This is the tsne of the test data. The encoder does not overfit, as the two look very similar.</p>   
          <p><img src="images/test-tsne.jpg" style="width:100%; max-width: 1000px;" class="images"></p>    
          <div style="text-align:center">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'exp')"><button class="close">Collapse</button></a>
          </div>
        </div>
      </div>
      <!-- lockheed -->
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'Lockheed-Martin')"><div id="slideselect"><h2>Lockheed Martin</h2></div></a>
        <p>June 2017 - August 2017</p>
        <p>Automated USPS driver monitoring for illegal/reckless driving using GPS data. Researched and wrote an image/signal processing program to recognize enemy radar chirps in electronic warfare.</p>
        <div style="text-align:center" id="Lockheed-Martin-expand">
          <a href="javascript:void(0)" onclick="slideOpen(event, 'Lockheed-Martin')"><button class="close">Expand</button></a>
        </div>
        <div class="rolldown" id="Lockheed-Martin">
          <h3>Automated driver monitoring</h3>
          <p>Automated USPS driver monitoring for illegal/reckless driving using noisy GPS data. The program was designed to detect left turns and U-turns in the routes and map out their locations. </p>
          <h3>Cognitive radar classification</h3>
          <p>Researched and wrote an image/signal processing program to recognize enemy radar chirps in electronic warfare. The program receives a radar signal, transforms it into a spectrogram image, then filters that image and applies computer vision techniques to create recognizable features. A machine learning neural net then uses the processed image to classify incoming radar as different adversaries. Wrote and tested the program in C++ for industrial use after testing concepts in MATLAB.
          <img src="images/lockheedRadar.png" style="width:100%; max-width: 1000px; padding: 15px 0 0 0;" class="images">
          </p>
          <div style="text-align:center">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'Lockheed-Martin')"><button class="close">Collapse</button></a>
          </div>
        </div>
      </div>
      <!-- school -->
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'school-projects')"><div id="slideselect"><h2>School Projects</h2></div></a>
        <p>Final projects for some my courses, demonstrated here with photos and video. </p>
        <div style="text-align:center" id="school-projects-expand">
          <a href="javascript:void(0)" onclick="slideOpen(event, 'school-projects')"><button class="close">Expand</button></a>
        </div>
        <div class="rolldown" id="school-projects">
          <h3>ECE 3140: Embedded Systems</h3>
          <p>The final project here was using the FRDM kinetis k64f to light up an LED display. The difficulty here involved programming the board to be able to transmit i2c signals.</p>
          <iframe width="560" height="315" src="https://www.youtube.com/embed/YPHC3Jr1OYA" frameborder="0" allowfullscreen style="padding: 15px 0 0 0"></iframe>
          <h3>ECE 3400: Robot Competition</h3>
          <p>In this class, a group of 8 students and I had a project of making a self navigating robot that could navigate a maze like that shown in the video below. The robot was able to send a radio signal of its current location as well as the location of an infrared emitter located on the maze.</p>
          <p>
            <video class="video-index" preload="auto" controls="true" type="video/mp4" style="height:400px">
              <source src="images/robot-race.mp4">
            </video>
          </p>
          <h3>ECE 4250: Super Resolution Imaging</h3>
          <p>For this project, our group took multiple images of my room, calibrated them, added them, and averaged them to obtain an image with more information than any single image. This was supported with some image SNR metrics. <a href="https://docs.google.com/presentation/d/15F1XexYetpaGs4-ytYM74lFMtaI1FJfvd40XvJmVDE4/edit?usp=sharing" target="_blank">Here</a> is a link to the presentation for more information.
          <p><img src="images/4250project.jpg" style="width:100%; max-width: 1000px; padding: 15px 0 0 0;" class="images"></p>
          </p>
          <div style="text-align:center">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'school-projects')"><button class="close">Collapse</button></a>
          </div>
        </div>
      </div>
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'via-project')"><div id="slideselect"><h2>Vision and Image Analysis Group: Research with Professor Anthony Reeves in Computer Vision</h2></div></a>
        <p>Jan 2016 - May 2017</p>
        <p>Studying computer vision and algorithm optimization using the VisionX Computer Vision and Image Processing System with the end goal of recognizing tumors in CT scans of lungs and determining their coordinates. These programs were written using tools from the VisionX software and in C.</p>
          <div style="text-align:center" id="via-project-expand">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'via-project')"><button class="close">Expand</button></a>
          </div>
          <div class="rolldown" id="via-project">
            <h3>Identifying airways in lung CT scans and determining their orientation</h3>
            <div class="container-stretch">
              <p>This is one slice of a CT scan of the chest. The two darker lobes in the image are the lungs, and the white parts within them are mostly vessels and airways. These images were taken from The Cancer Imaging Archive <sup><a href="#tcia-cite" style="text-decoration:none">[1]</a></sup></p>
              <p><img src="images/ct.png" style="width:100%; max-width: 1000px;" class="images"></p>
            </div>
            <div class="container-stretch">
              <p>This is a slice of a airway, zoomed in. The filled in circle is a blood vessel, and the hollow circle is an airway.</p>
              <img src="images/airway.png" style="width:150px" class="images">
            </div>
            <div class="container-stretch">
              <p>I am writing a program to differentiate between airways and air pockets, so that the overal program will be able to tell if the lung CT has air outiside of the airways and lung air sacs (alveoli). This diagram demonsrates what is meant by "orientation of an airway". Another program developed by the Vision and Image analysis group is able to point out locations of sphere shaped pockets of air within the lung, and their radii. Airways trigger this program and their locations are listed within the large list of locations of air pockets.An airway candidate can be determined by using moments analysis. Because a sphere intersecting with a cylinder (the assumed model of an airway) is a ring, this ring can be seen and interpreted by the program. </p>
              <img src="images/sphere-cylinder.png" style="width:300px" class="images">
            </div>
            <img src="images/diagramalgorithm.png" style="width:100%; max-width: 1000px;" class="images">
            <div class="container-stretch">
              <h3>Canny edge detection in 3D</h3>
              <p> I wrote a program which has the purpose of creating a 3D boundary between two regions in a 3D image. This program takes in the gradient and performs non maximum suppression and thresholding with hysteresis on a 3D gradient file. This image is a slice of a noisy sphere generated using the VisionX software system for image processing and computer vision. On the left, a sphere added onto a background in a 3D image. In the center, that same sphere with added noise. One the right, the gradient magnitude of the image with added noise. </p>
              <img src="images/noisysphere.png" style="width:100%; max-width: 1000px;" class="images">
            </div>
            <div class="container-stretch">
              <p>This image is a slice of the sphere, zoomed in, and demonstrating non maximum suppression to obtain a 1 pixel thick edge. On the left, the original image section, zoomed in. In the center, the same region after the applied non-maximum suppression. On the right, the image of the difference between the original and the image after the program (red pixels are the same as the original, green pixels have been removed by the program).</p>
              <img src="images/nms.png" style="width:100%; max-width: 1000px;" class="images">
            </div>
            <a class="anchor"  id="tcia-cite"></a>
            <div class="container-stretch">
              <p><sup>[1]</sup>The Cancer Imaging Archive (TCIA) citation</p>
              <p>Clark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. <b>The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository</b>, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057.</p>
              <p><sup>[1]</sup>Data Citation</p>
              <p>Grove, Olya, Berglund, Anders E., Schabath, Matthew B., Aerts, Hugo J.W.L., Dekker, Andre, Wang, Hua, â€¦ Gillies, Robert J. (2015). Data from: Quantitative computed tomographic descriptors associate tumor shape complexity and intratumor heterogeneity with prognosis in lung adenocarcinoma. The Cancer Imaging Archive. <a href="http://doi.org/10.7937/K9/TCIA.2015.A6V7JIWX">http://doi.org/10.7937/K9/TCIA.2015.A6V7JIWX</a></p>
            </div>
            <div style="text-align:center">
              <a href="javascript:void(0)" onclick="slideOpen(event, 'via-project')"><button class="close">Collapse</button></a>
            </div>
          </div>
      </div>
      <!-- leidos -->
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'leidos-project')"><div id="slideselect"><h2>Leidos</h2></div></a>
        <p> May 2016 - Aug 2016</p>
        <p>Helped Leidos develop their synthetic aperture and plenoptic processing capabilities. All projects were involving image processing in MATLAB.</p>
        <div style="text-align:center" id="leidos-project-expand">
          <a href="javascript:void(0)" onclick="slideOpen(event, 'leidos-project')"><button class="close">Expand</button></a>
        </div>
        <div class="rolldown" id="leidos-project">
          <h3> Occlusion Penetrating Imaging</h3>
          <p> The goal of this image was to be able to take spy plane images, and track partially occluded targets. Taking multiple images of a scene, camera locations, and object
            distance, this program will stitch together the scene behind the occluding object (often foliage) by overlaying the images with the pixel displacement to match the distance given and the camera positions. I tested this algorithm by taking images on my own cell phone of occluded scenes, and calibrating them to eliminate rotation or translational inaccuracies. I wrote the calibration and stitching programs in MATLAB.</p>
            <p>Source images, after rotation and translational calibration to overcome the jitter that comes with acquiring these images on a cell phone.</p>
          <video class="video-index" preload="auto" controls="true" type="video/mp4">
            <source src="images/leidos-building-compressed.mp4">
          </video>
          <p>This video focuses the images at a specific distance, by moving them on top of each other and averaging the pixel values. Partially occluded objects can be made out because they are usually not occluded in every single image. The "College Park" text and building become much more clear behind the bush. The displayed video is the overlayed images with the depth given at the top of the image in millimeters.</p>
          <div class="container-stretch"> 
            <video class="video-index" preload="auto" controls="true" type="video/mp4">
              <source src="images/range-sweep3.mp4">
            </video>
          </div>
          <div class="container-stretch" controls="true">
            <h3>3D Point Cloud Generation</h3>
            <p>This program takes images of an object taken from different angles and generates a 3D model. It detects distance to every object in an image based on pixel disparity from multiple images of the object and known camera locations using stereo vision type range calculation with kernel matching. I wrote the function to discover pixel disparity using phase shift in the frequency domain.</p>
            <p>Source images of a lego truck</p>
            <video class="video-index" preload="auto" controls="true" type="video/mp4">
              <source src="images/truck.mp4">
            </video>
          </div>
          <div class="container-stretch">
            <p>Corresponding generated 3D point Cloud</p>
            <video class="video-index" preload="auto" controls="true" type="video/mp4">
              <source src="images/truck-cloud.mp4">
            </video>
          </div>
          <div style="text-align:center">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'leidos-project')"><button class="close">Collapse</button></a>
          </div>
        </div>
      </div>
      <!-- website -->
      <div class="container-stretch">
        <div id="slideselect"><h2>This Website</h2></div>
        <p> Jan 2017 - Present</p>
        <div class="rolldown-website" id="website-project">
          <a href="https://github.com/ryx2/ryx2.github.io">
            <img src="images/github.png" class="project-images">
          </a>
          <div id="float-left">
            <p id="container-pad">I wrote the code for this website in html/css/js. It is available for viewing on <a href="https://github.com/ryx2/ryx2.github.io">github</a>.</p>
          </div>
        </div>
      </div>
      <!-- ruina -->
      <div class="container-stretch">
        <a href="javascript:void(0)" class="slider" onclick="slideOpen(event, 'motion-project')"><div id="slideselect"><h2>Biorobotics and Locomotion Lab</h2></div></a>
        <p> May 2015 - Aug 2015</p>
        <p>Researched human balance while standing, walking, running, and turning using pressure sensitive force plates. The eventual goal of the project was to be able to understand how to make a walking robot by understanding how the center of mass of a human walking changed during the gait. Beginning to move in any direction was modeled after an upside-down pendulum, or inverse pendulum (before a person moved in any direction they would have to take a step in the opposite direciton to cause them to lean in the direction they would like to move in). </p>
        <div style="text-align:center" id="motion-project-expand">
          <a href="javascript:void(0)" onclick="slideOpen(event, 'motion-project')"><button class="close">Expand</button></a>
        </div>
        <div class="rolldown" id="motion-project">
          <p>This program in MATLAB that read the data and created scatter plots to model where the feet were on the force plate over time. In this particular trial, the person was instructed to run right. Before running right, the person leans left, which follows the inverse pendulum model.</p>
          <img src="images/motion2.png" style="width:600px"class="images">
          <div style="text-align:center">
            <a href="javascript:void(0)" onclick="slideOpen(event, 'motion-project')"><button class="close">Collapse</button></a>
          </div>
        </div>
      </div>
    </div>
    </body>
  <script src="scripts/main.js"></script>
</html>